
# **California Housing Optimization with Optuna and XGBoost**

Este proyecto implementa un modelo de machine learning utilizando **XGBoost** para predecir el precio medio de viviendas en California, optimizando los hiperpar√°metros con **Optuna** y registrando los resultados en **MLflow**. Este documento incluye la descripci√≥n del proyecto, los pasos para ejecutarlo, y las conclusiones derivadas del an√°lisis.

---

## **Estructura del Proyecto**

```
california_housing_optuna/
‚îú‚îÄ‚îÄ california_housing_optuna/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py        # Archivo de inicializaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # C√≥digo principal
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py        # Archivo de inicializaci√≥n para pruebas
‚îú‚îÄ‚îÄ pyproject.toml         # Configuraci√≥n del entorno de Poetry
‚îî‚îÄ‚îÄ README.md              # Documentaci√≥n general
```

---

## **Requisitos**

- **Python 3.8 o superior**
- **Poetry** para la gesti√≥n del entorno virtual

### **Instalaci√≥n de Dependencias**
1. Instala **Poetry** si a√∫n no lo tienes:
   ```bash
   pip install poetry
   ```

2. Instala las dependencias del proyecto:
   ```bash
   poetry install
   ```

---

## **Ejecuci√≥n del Proyecto**

1. Activa el entorno virtual de Poetry:
   ```bash
   poetry shell
   ```

2. Ejecuta el archivo principal:
   ```bash
   poetry run python california_housing_optuna/main.py
   ```

---

## **Librer√≠as Usadas**

- **Optuna**: Optimizaci√≥n de hiperpar√°metros.
- **XGBoost**: Modelo basado en boosting para predicci√≥n.
- **Scikit-learn**: Divisi√≥n de datos y c√°lculo de m√©tricas.
- **MLflow**: Registro de experimentos y modelos.
- **Matplotlib** y **Seaborn**: Visualizaci√≥n de datos.

---

## **Flujo del Proyecto**

1. **Carga de Datos**:
   - El dataset `California Housing` es cargado desde `sklearn`.
   - Los datos se dividen en conjuntos de entrenamiento (80%) y prueba (20%).

2. **Optimizaci√≥n con Optuna**:
   - Se optimizan los hiperpar√°metros del modelo **XGBoost** en 50 combinaciones mediante b√∫squeda aleatoria.

3. **Entrenamiento y Evaluaci√≥n**:
   - Se entrena el modelo con los mejores hiperpar√°metros encontrados.
   - Se eval√∫an las m√©tricas clave: **RMSE** y **R¬≤**.

4. **Registro con MLflow**:
   - Se registran los par√°metros, m√©tricas y el modelo final en MLflow para trazabilidad.

---

## **Resultados Finales**

### **Mejores Hiperpar√°metros Encontrados**
```plaintext
{'max_depth': 9, 'learning_rate': 0.13, 'n_estimators': 272, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 6.66, 'reg_lambda': 7.90}
```

### **M√©tricas del Modelo Final**
| M√©trica           | Entrenamiento | Prueba     |
|-------------------|---------------|------------|
| **RMSE**          | `0.2741`      | `0.4390`   |
| **R¬≤**            | `97.15%`      | `85.29%`   |

---

## **Interpretaci√≥n**

1. **Regularizaci√≥n Efectiva**:
   - Los valores altos de `reg_alpha` y `reg_lambda` (6.66 y 7.90 respectivamente) ayudaron a controlar el sobreajuste.

2. **Capacidad Predictiva**:
   - El **R¬≤ de prueba** indica que el modelo explica el 85.29% de la varianza en los datos no vistos, lo que es un excelente desempe√±o.

3. **Optimizaci√≥n con Optuna**:
   - Optuna permiti√≥ encontrar una configuraci√≥n √≥ptima de hiperpar√°metros en solo 50 pruebas.

4. **Evaluaci√≥n General**:
   - El modelo generaliza bien, con un error promedio bajo en la predicci√≥n de precios.

---

## **Gr√°ficos de Resultados**

El proyecto incluye gr√°ficos de:
- **Distribuci√≥n de datos**: Para validar la calidad y normalizaci√≥n del dataset.
- **Residuos del modelo**: Para evaluar errores en las predicciones.
- **L√≠nea ideal vs Predicciones**: Para visualizar la cercan√≠a entre predicciones y valores reales.

---

## **Conclusiones**

1. **Uso de Optuna**:
   - La optimizaci√≥n autom√°tica con Optuna simplifica la selecci√≥n de hiperpar√°metros, mejorando el desempe√±o del modelo en menos tiempo.

2. **Registro con MLflow**:
   - Permite reproducibilidad y facilita la comparaci√≥n de experimentos.

3. **Rendimiento del Modelo**:
   - El RMSE de prueba de `0.4390` y un R¬≤ de `85.29%` muestran que el modelo es preciso y generaliza bien en datos no vistos.

4. **Mejoras Futuras**:
   - Probar t√©cnicas de ensamblado (stacking o blending).
   - Incorporar validaci√≥n cruzada para mejorar la robustez del modelo.
   - Experimentar con caracter√≠sticas adicionales derivadas de datos externos.

---

## **Exploraci√≥n con MLflow**

1. Inicia el servidor de MLflow:
   ```bash
   mlflow ui
   ```

2. Accede al dashboard:
   - URL: [http://127.0.0.1:5000](http://127.0.0.1:5000)

3. Explora los experimentos registrados para comparar m√©tricas y par√°metros.

---

## **Siguientes Pasos**
1. **Validaci√≥n Adicional**:
   - Implementar validaci√≥n cruzada para garantizar que el modelo generalice mejor.
   
2. **Comparaci√≥n de Modelos**:
   - Implementar otros algoritmos como Gradient Boosting o Random Forest.

3. **Despliegue en Producci√≥n**:
   - Usar el modelo registrado en MLflow para implementar un sistema de predicci√≥n en tiempo real.

Este proyecto es un ejemplo s√≥lido de c√≥mo usar herramientas modernas como **Optuna** y **MLflow** para resolver problemas complejos de machine learning. üöÄ
